{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 圖片分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:49.138443Z",
     "start_time": "2023-05-08T10:16:48.359395Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 建立目標資料夾\n",
    "if not os.path.exists('./my_images'):\n",
    "    os.mkdir('./my_images')\n",
    "\n",
    "# 遍歷資料夾中的檔案\n",
    "for filename in os.listdir('./hiragana_images'):\n",
    "    # 判斷檔案是否為 jpg 檔\n",
    "    if filename.endswith('.jpg'):\n",
    "        # 取得檔名中的非數字字元\n",
    "        class_name = os.path.splitext(''.join(filter(lambda x: not x.isdigit(), filename)))[0]\n",
    "        # 建立目標資料夾\n",
    "        target_folder = os.path.join('./my_images', class_name)\n",
    "        if not os.path.exists(target_folder):\n",
    "            os.mkdir(target_folder)\n",
    "        # 複製檔案到對應的資料夾中\n",
    "        shutil.copy(os.path.join('./hiragana_images', filename), os.path.join(target_folder, filename))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:51.801130200Z",
     "start_time": "2023-05-08T10:16:49.138443Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:51.804839800Z",
     "start_time": "2023-05-08T10:16:51.803329500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 超參數\n",
    "\n",
    "num_classes = 50  # 50音分類\n",
    "batch_size = 20  #訓練樣本數\n",
    "num_epochs = 30  #一期訓練  Iteration = （Data set size / Batch size）* Epoch = (1000/20)*10 = 5000\n",
    "learning_rate = 0.001 #學習率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:51.808548400Z",
     "start_time": "2023-05-08T10:16:51.806841Z"
    }
   },
   "outputs": [],
   "source": [
    "# 數據預處理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # 調整大小為 32x32\n",
    "    transforms.Grayscale(num_output_channels=1),  # 轉為單通道灰度圖像\n",
    "    transforms.ToTensor()  # 轉為張量\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 載入數據 並將數據分配測試集和訓練集 8:2\n",
    "train_dataset = datasets.ImageFolder(root='./my_images', transform=transform) # datasets.ImageFolder 會將資料夾中的圖片依照資料夾名稱分類\n",
    "train_data, test_data = train_test_split(train_dataset, test_size=0.2, random_state=42) #train_test_split 會將資料分成兩部分，一部分用來訓練，一部分用來測試\n",
    "#訓練集\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  #每次訓練數量 = Data set size(*0.8) / Batch size = 800/20 = 40\n",
    "#測試集\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # 載入數據\n",
    "# train_dataset = datasets.ImageFolder(root='F:\\pycharm_pro\\pytorch_learn\\my_images', transform=transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:52.310928500Z",
     "start_time": "2023-05-08T10:16:51.811547400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 定義模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4*4*128, 256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 50)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:52.316569500Z",
     "start_time": "2023-05-08T10:16:52.315564600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             320\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "              ReLU-3           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 32, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]          18,496\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-8             [-1, 64, 8, 8]               0\n",
      "            Conv2d-9            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-10            [-1, 128, 8, 8]             256\n",
      "             ReLU-11            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-12            [-1, 128, 4, 4]               0\n",
      "           Linear-13                  [-1, 256]         524,544\n",
      "          Dropout-14                  [-1, 256]               0\n",
      "             ReLU-15                  [-1, 256]               0\n",
      "           Linear-16                   [-1, 50]          12,850\n",
      "================================================================\n",
      "Total params: 630,514\n",
      "Trainable params: 630,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.43\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 3.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 實例化模型、損失函數和優化器\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#可視化模型\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 32, 32), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:16:52.336897800Z",
     "start_time": "2023-05-08T10:16:52.317569400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:17:16.850788600Z",
     "start_time": "2023-05-08T10:16:52.337896300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30],                     Step [10/40],                     Loss: 3.6558\n",
      "Epoch [1/30],                     Step [20/40],                     Loss: 3.2927\n",
      "Epoch [1/30],                     Step [30/40],                     Loss: 2.7561\n",
      "Epoch [1/30],                     Step [40/40],                     Loss: 1.9224\n",
      "Epoch [2/30],                     Step [10/40],                     Loss: 1.2578\n",
      "Epoch [2/30],                     Step [20/40],                     Loss: 1.2346\n",
      "Epoch [2/30],                     Step [30/40],                     Loss: 0.9538\n",
      "Epoch [2/30],                     Step [40/40],                     Loss: 0.6365\n",
      "Epoch [3/30],                     Step [10/40],                     Loss: 0.3602\n",
      "Epoch [3/30],                     Step [20/40],                     Loss: 0.3572\n",
      "Epoch [3/30],                     Step [30/40],                     Loss: 0.1810\n",
      "Epoch [3/30],                     Step [40/40],                     Loss: 0.1607\n",
      "Epoch [4/30],                     Step [10/40],                     Loss: 0.1203\n",
      "Epoch [4/30],                     Step [20/40],                     Loss: 0.0987\n",
      "Epoch [4/30],                     Step [30/40],                     Loss: 0.1845\n",
      "Epoch [4/30],                     Step [40/40],                     Loss: 0.3446\n",
      "Epoch [5/30],                     Step [10/40],                     Loss: 0.0687\n",
      "Epoch [5/30],                     Step [20/40],                     Loss: 0.0635\n",
      "Epoch [5/30],                     Step [30/40],                     Loss: 0.0662\n",
      "Epoch [5/30],                     Step [40/40],                     Loss: 0.0440\n",
      "Epoch [6/30],                     Step [10/40],                     Loss: 0.0279\n",
      "Epoch [6/30],                     Step [20/40],                     Loss: 0.0431\n",
      "Epoch [6/30],                     Step [30/40],                     Loss: 0.0374\n",
      "Epoch [6/30],                     Step [40/40],                     Loss: 0.0371\n",
      "Epoch [7/30],                     Step [10/40],                     Loss: 0.0354\n",
      "Epoch [7/30],                     Step [20/40],                     Loss: 0.0231\n",
      "Epoch [7/30],                     Step [30/40],                     Loss: 0.0239\n",
      "Epoch [7/30],                     Step [40/40],                     Loss: 0.0236\n",
      "Epoch [8/30],                     Step [10/40],                     Loss: 0.0102\n",
      "Epoch [8/30],                     Step [20/40],                     Loss: 0.0139\n",
      "Epoch [8/30],                     Step [30/40],                     Loss: 0.0244\n",
      "Epoch [8/30],                     Step [40/40],                     Loss: 0.0386\n",
      "Epoch [9/30],                     Step [10/40],                     Loss: 0.0451\n",
      "Epoch [9/30],                     Step [20/40],                     Loss: 0.0326\n",
      "Epoch [9/30],                     Step [30/40],                     Loss: 0.0151\n",
      "Epoch [9/30],                     Step [40/40],                     Loss: 0.0142\n",
      "Epoch [10/30],                     Step [10/40],                     Loss: 0.1011\n",
      "Epoch [10/30],                     Step [20/40],                     Loss: 0.0220\n",
      "Epoch [10/30],                     Step [30/40],                     Loss: 0.0094\n",
      "Epoch [10/30],                     Step [40/40],                     Loss: 0.0028\n",
      "Epoch [11/30],                     Step [10/40],                     Loss: 0.0054\n",
      "Epoch [11/30],                     Step [20/40],                     Loss: 0.0027\n",
      "Epoch [11/30],                     Step [30/40],                     Loss: 0.0040\n",
      "Epoch [11/30],                     Step [40/40],                     Loss: 0.0089\n",
      "Epoch [12/30],                     Step [10/40],                     Loss: 0.0074\n",
      "Epoch [12/30],                     Step [20/40],                     Loss: 0.0064\n",
      "Epoch [12/30],                     Step [30/40],                     Loss: 0.0456\n",
      "Epoch [12/30],                     Step [40/40],                     Loss: 0.0070\n",
      "Epoch [13/30],                     Step [10/40],                     Loss: 0.0100\n",
      "Epoch [13/30],                     Step [20/40],                     Loss: 0.0042\n",
      "Epoch [13/30],                     Step [30/40],                     Loss: 0.0080\n",
      "Epoch [13/30],                     Step [40/40],                     Loss: 0.0101\n",
      "Epoch [14/30],                     Step [10/40],                     Loss: 0.0094\n",
      "Epoch [14/30],                     Step [20/40],                     Loss: 0.0055\n",
      "Epoch [14/30],                     Step [30/40],                     Loss: 0.0071\n",
      "Epoch [14/30],                     Step [40/40],                     Loss: 0.0079\n",
      "Epoch [15/30],                     Step [10/40],                     Loss: 0.0049\n",
      "Epoch [15/30],                     Step [20/40],                     Loss: 0.0222\n",
      "Epoch [15/30],                     Step [30/40],                     Loss: 0.0365\n",
      "Epoch [15/30],                     Step [40/40],                     Loss: 0.0104\n",
      "Epoch [16/30],                     Step [10/40],                     Loss: 0.0054\n",
      "Epoch [16/30],                     Step [20/40],                     Loss: 0.0057\n",
      "Epoch [16/30],                     Step [30/40],                     Loss: 0.0094\n",
      "Epoch [16/30],                     Step [40/40],                     Loss: 0.0050\n",
      "Epoch [17/30],                     Step [10/40],                     Loss: 0.0433\n",
      "Epoch [17/30],                     Step [20/40],                     Loss: 0.0052\n",
      "Epoch [17/30],                     Step [30/40],                     Loss: 0.0582\n",
      "Epoch [17/30],                     Step [40/40],                     Loss: 0.0031\n",
      "Epoch [18/30],                     Step [10/40],                     Loss: 0.0017\n",
      "Epoch [18/30],                     Step [20/40],                     Loss: 0.0020\n",
      "Epoch [18/30],                     Step [30/40],                     Loss: 0.0138\n",
      "Epoch [18/30],                     Step [40/40],                     Loss: 0.0040\n",
      "Epoch [19/30],                     Step [10/40],                     Loss: 0.0059\n",
      "Epoch [19/30],                     Step [20/40],                     Loss: 0.0017\n",
      "Epoch [19/30],                     Step [30/40],                     Loss: 0.0003\n",
      "Epoch [19/30],                     Step [40/40],                     Loss: 0.0030\n",
      "Epoch [20/30],                     Step [10/40],                     Loss: 0.0022\n",
      "Epoch [20/30],                     Step [20/40],                     Loss: 0.0041\n",
      "Epoch [20/30],                     Step [30/40],                     Loss: 0.0006\n",
      "Epoch [20/30],                     Step [40/40],                     Loss: 0.0054\n",
      "Epoch [21/30],                     Step [10/40],                     Loss: 0.0008\n",
      "Epoch [21/30],                     Step [20/40],                     Loss: 0.0055\n",
      "Epoch [21/30],                     Step [30/40],                     Loss: 0.0025\n",
      "Epoch [21/30],                     Step [40/40],                     Loss: 0.0020\n",
      "Epoch [22/30],                     Step [10/40],                     Loss: 0.0007\n",
      "Epoch [22/30],                     Step [20/40],                     Loss: 0.0008\n",
      "Epoch [22/30],                     Step [30/40],                     Loss: 0.0038\n",
      "Epoch [22/30],                     Step [40/40],                     Loss: 0.0007\n",
      "Epoch [23/30],                     Step [10/40],                     Loss: 0.0056\n",
      "Epoch [23/30],                     Step [20/40],                     Loss: 0.0056\n",
      "Epoch [23/30],                     Step [30/40],                     Loss: 0.0007\n",
      "Epoch [23/30],                     Step [40/40],                     Loss: 0.0029\n",
      "Epoch [24/30],                     Step [10/40],                     Loss: 0.0029\n",
      "Epoch [24/30],                     Step [20/40],                     Loss: 0.0015\n",
      "Epoch [24/30],                     Step [30/40],                     Loss: 0.0098\n",
      "Epoch [24/30],                     Step [40/40],                     Loss: 0.0138\n",
      "Epoch [25/30],                     Step [10/40],                     Loss: 0.0112\n",
      "Epoch [25/30],                     Step [20/40],                     Loss: 0.0024\n",
      "Epoch [25/30],                     Step [30/40],                     Loss: 0.0083\n",
      "Epoch [25/30],                     Step [40/40],                     Loss: 0.0062\n",
      "Epoch [26/30],                     Step [10/40],                     Loss: 0.0227\n",
      "Epoch [26/30],                     Step [20/40],                     Loss: 0.0011\n",
      "Epoch [26/30],                     Step [30/40],                     Loss: 0.0032\n",
      "Epoch [26/30],                     Step [40/40],                     Loss: 0.0026\n",
      "Epoch [27/30],                     Step [10/40],                     Loss: 0.0109\n",
      "Epoch [27/30],                     Step [20/40],                     Loss: 0.0059\n",
      "Epoch [27/30],                     Step [30/40],                     Loss: 0.0084\n",
      "Epoch [27/30],                     Step [40/40],                     Loss: 0.0193\n",
      "Epoch [28/30],                     Step [10/40],                     Loss: 0.0148\n",
      "Epoch [28/30],                     Step [20/40],                     Loss: 0.0202\n",
      "Epoch [28/30],                     Step [30/40],                     Loss: 0.0085\n",
      "Epoch [28/30],                     Step [40/40],                     Loss: 0.0034\n",
      "Epoch [29/30],                     Step [10/40],                     Loss: 0.0246\n",
      "Epoch [29/30],                     Step [20/40],                     Loss: 0.1779\n",
      "Epoch [29/30],                     Step [30/40],                     Loss: 0.1329\n",
      "Epoch [29/30],                     Step [40/40],                     Loss: 0.0015\n",
      "Epoch [30/30],                     Step [10/40],                     Loss: 0.0193\n",
      "Epoch [30/30],                     Step [20/40],                     Loss: 0.0096\n",
      "Epoch [30/30],                     Step [30/40],                     Loss: 0.0115\n",
      "Epoch [30/30],                     Step [40/40],                     Loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 前向傳播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向傳播和優化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
    "                    Step [{i+1}/{total_step}], \\\n",
    "                    Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:17:16.918079400Z",
     "start_time": "2023-05-08T10:17:16.852788400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.5 %\n"
     ]
    }
   ],
   "source": [
    "# 測試模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:17:16.924664600Z",
     "start_time": "2023-05-08T10:17:16.919080300Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), '50on_model.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 手寫測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T10:17:16.935249300Z",
     "start_time": "2023-05-08T10:17:16.927663500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=83x84>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAABUCAIAAABx1ZzvAAAD+0lEQVR4nO1Z25KrIBAcAU3+/2+jguehy65eiJusuZjKmX5IEUWZYW49aOZwOBwOh8PhcDgcDofD4XA4HA6H4+PRdR0Gfd/jbwiBdznGgJO/BDFGqgQN+75XVan/V2meUjKzEEKlVWt5vfIlgJ+nlKC/bgGcv7L8l0D1jDHO87ysaKd9m/JmNgzDsizTNIUQqPOyLF3Xnc9nMwshxBgPlfHZgHkvlwu8upQCzdvfbwN1m6Yp5wzDhhBKKbgeY8R2fLr+CEhGLytWdR1YliWlNI4jFIa2mMYdof/3fT/PM5+tkr9WvrZSvBUqDRRjoKaU4NhmlnPGNNylxCo6DD6OoyY/TEBdIFAjcffdykON0+nEv+QkSk5SSqUUZvJ5nnWbsAspJW4WjG9mMDu9g0uQAnZdV230+0DHhjSUgFbqug5pHJ6sjJWT9SnVAVuAjFBK2bItjf8+aITrRfKwcRw5rZRSMXNbY8Eaj8V1hEmMcRzHeZ5TSnQcev4wDK9W8wquthbchRBCSomxil/qrEHL98B6VZrEG5j8OKjWrbLAa1HZXNMshGO50kc0UdPUGgK6oTDp5XKxpuDTX46hPWphDCojU1CNYW1Lqu3ThM9pmjJzzkqBuHHH6A+xcs62mhHyqd/uk6xNDbqz8Km2wpsEy0sKHt6L4IRApRTozHL1yPJb0YRVkPBNnKuqLNbkgiejWmZZlpwzsxE9dkfv1Xaytu7C+Xyugh/TSC605u/X7XfhuLbybSR2lXWHt29VTQzoa6WUUso0TRg/HmK3oayLYqkLVAdPj0CZkhY/rt73fYwRrOnl3Ab6aMqheTUzm9SqHe8nV6m6g8qe8zwj5yPRYs6rivw4jsMw5JzZb9lP8z6rkdL3qM7YFHJnW50fzOeF6Y0bDLVp2KpQdyv++v6q292iupxMkp9zRpZ9QpxrnSSjZiVr+cyBgMHB8Kv6qoe/f7OEhivUZlDZB5wcqmwVcSZBrJjibegXAr6dwJIHdIsN2A63PG+LJt8FplmktK3EdhSqhr89z9Owv0tgphYTomZmPHIw2cjXEsZboG3V7PDK/S6pqQIGv5o5D9dcB63Z8XnH7pdTjz7wTM55mibSKQyOOSH5KZitDjgMg+a5KlXd5e1slWwl6srSH8ocz0bbpWkHZWs43Fvntfvd6k+qwVH4pZ+/evc2NMLV1GQ4bW/8fmz187ZbTmYLzMZngNZnkNiPZTJX+/lH5WR5IB/WNT7Q5ry4X07NFuDD1YveeuJ7H6ovH/vlZGzzbIAsnW6DknY4b7/az++UE/HDOCfUcw7P6oqtfv4hObv1IyH/6tg+IM7bft4+TE6Hw+FwOBwOh8PhcDgcDofjv8Q/cm5pZdkv5aIAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測結果:kanaHE\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# 轉換圖片\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # 調整大小為 32x32\n",
    "    transforms.Grayscale(num_output_channels=1),  # 轉為單通道灰度圖像\n",
    "    transforms.ToTensor()  # 轉為張量\n",
    "])\n",
    "\n",
    "# 載入圖片\n",
    "img = Image.open('./test_images/HE.jpg')\n",
    "display(img)\n",
    "img = test_transform(img)\n",
    "\n",
    "\n",
    "# 增加一維，批次大小設為 1\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# 使用訓練好的模型進行預測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "    pred = output.argmax(dim=1)\n",
    "\n",
    "\n",
    "label_dict = train_dataset.class_to_idx\n",
    "reverse_label_dict = {v: k for k, v in label_dict.items()}\n",
    "print(f'預測結果:{reverse_label_dict[pred.item()]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
